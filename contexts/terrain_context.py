import pandas as pd
import glob
import numpy as np
from PIL import Image
import time
import os
import json
import subprocess
from cfg.base_config import *
from rl_agents.teacher_net import transform_depth_image
from denoising_diffusion_pytorch import Unet, GaussianDiffusion
from contexts.terrain_utils import * 
from utils import *
import torchvision.models as models
import torch

class TerrainContext:
    def __init__(self, context_space: BaseVehicleCfg.context):
        """
        A context is sampled at the beginning of each episode. It modifies the transition and the reward functions.
        In the current implementation, the context includes (1) physical parameters and (2) environment parameters.
        The physical parameters are sampled from a uniform distribution.
        The sampling distribution of environment parameters is defined by the sample_mode
            (1) 'uniform': uniform distribution
            (2) 'isaac': the random terrain generated by the Isaac Gym terrain utility
            (3) 'data': the terrain is sampled from a dataset
            (4) 'diffusion': diffusion model
            (5) 'guided_diffusion': a diffusion model guided by the robot's performance
        """
        self.device = DEVICE
        self.context_space = context_space
        self.environment_sampler = self.context_space.environment.sampler
        self.environment_curriculum = self.context_space.environment.curriculum
        self.num_rows = self.context_space.environment.num_rows
        self.num_cols = self.context_space.environment.num_cols
        self.num_terrains = self.num_rows * self.num_cols
        self.num_rows_per_env = self.context_space.environment.num_rows_per_env
        self.num_cols_per_env = self.context_space.environment.num_cols_per_env
        self.x_res = self.context_space.environment.x_res
        self.y_res = self.context_space.environment.y_res
        self.z_scale = self.context_space.environment.z_scale
        self.terrain_width = self.num_cols_per_env * self.x_res
        self.terrain_height = self.num_rows_per_env * self.y_res
        self.difficulty = 0
        self.heightfields = []
        self.frictions = []
        self.restitutions = []

    def encoder(self, num_agents_per_terrain):
        resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT).to(self.device)
        for param in resnet.parameters():
            param.requires_grad = False

        self.encoded_heightfields = resnet(transform_depth_image(self.heightfields))
        self.encoded_heightfields = self.encoded_heightfields.repeat_interleave(num_agents_per_terrain, dim=0)
    
    def procedural_sample(self, choice=-1, difficulty=-1):
        """
        Resets the heightfield of the environments specified by diffuculty.
        """
        if choice == -1:
            choice = np.random.randint(0, len(self.context_space.environment.isaac_terrain_type))
        args = self.context_space.environment.isaac_terrain_args[choice]

        if difficulty < 0:
            difficulty = np.random.randint(0, 101)
        difficulty /= 100.
        
        if choice == 0:  # random_uniform_terrain
            args['max_height'] *= difficulty
            args['min_height'] *= difficulty
            args['step'] = 0.005 + (args['step'] - 0.005) * difficulty
            args['downsampled_scale'] = 0.1
        elif choice == 1:  # sloped_terrain
            args['slope'] = 0.05 + (args['slope'] - 0.05) * difficulty
        elif choice == 2:  # discrete_obstacles_terrain
            args['max_height'] = 0.2 + (args['max_height'] - 0.2) * difficulty
            args['num_rects'] = int(1 + (args['num_rects'] - 1) * difficulty)
        elif choice == 3:  # wave_terrain
            max_wave = args['num_waves']
            args['num_waves'] = int(1 + (args['num_waves'] - 1) * difficulty)
            args['amplitude'] = 0.1 + (max_wave/args['num_waves'] - 0.1) * difficulty
        
        new_terrain = SubTerrain('terrain', int(self.num_rows_per_env), int(self.num_cols_per_env), 1, self.x_res)
        new_terrain = self.context_space.environment.isaac_terrain_type[choice](new_terrain, **args)
        return new_terrain.height_field_raw

    def _id_to_idx(self, env_ids):
        """
        Converts the environment ID (a tensor with N elements) to the row and column indices of the environment.
        """
        row_id = env_ids // self.num_cols
        col_id = env_ids // self.num_rows
        return row_id, col_id

class TerrainContextSpace(TerrainContext):
    def __init__(self, context_space: BaseVehicleCfg):
        """
        The task context space represents the goal context of the robot.
        """
        super(TerrainContextSpace, self).__init__(context_space.context)

        self.epoch = 0
        self.start_time = 0
        self.method = self.environment_sampler + ' ' + self.environment_curriculum

        # Initialize the data DataFrame
        self.data = pd.DataFrame(columns=('image_name', 'suc_rate', 'episode', 'active'))
        self.evaluation = pd.DataFrame(columns=('episode', 'trajectory', 'reward', 'suc_rate'))

        if self.environment_sampler == 'nature':
            nature_files = glob.glob(os.path.join(self.context_space.environment.train_path, '**', '*.txt'), recursive=True)
            # Option 1: initialize all suc_rate to 0
            # Option 2: initialize all suc_rate to 0.1 (very hard) to excite exploration
            self.data = pd.DataFrame({
                'image_name': nature_files, 'suc_rate': 0.1,
                'episode': 0, 'active': False
            })
        elif self.environment_sampler == 'ddpm':
            self.model = Unet(
                dim = 16, channels = 1, dim_mults = (1, 2, 4)
            ).to(device=self.device)
            self.ddpm = GaussianDiffusion(
                self.model, image_size = self.num_rows_per_env,
                timesteps = 1000, sampling_timesteps = 125,
            ).to(device=self.device)
            current_dir = os.path.dirname(os.path.abspath(__file__))
            state_dict = torch.load(self.context_space.environment.ddpm_model_path, weights_only=True)
            self.ddpm.load_state_dict(state_dict['model'])
            self.model.eval()
            self.ddpm.eval()
    
    def get_backbone(self, index=None):
        index = index if index != None else self.epoch
        if index > 0:
            return "model/{}/{}.pt".format(self.method, str(index))
        return 'Nullptr'

    def to_dict(self):
        """
        Serialize the TerrainContextSpace object to a dictionary.
        """
        return {
            'environment_sampler': self.environment_sampler,
            'environment_curriculum': self.environment_curriculum,
            'method': self.method,
            'device': str(self.device),
            'num_rows': self.num_rows,
            'num_cols': self.num_cols,
            'num_terrains': self.num_terrains,
            'num_rows_per_env': self.num_rows_per_env,
            'num_cols_per_env': self.num_cols_per_env,
            'difficulty': self.difficulty,
            'epoch': self.epoch,
            'start_time': self.start_time,
            'data': self.data.to_dict(orient='list'),
            'evaluation': self.evaluation.to_dict(orient='list'),
        }

    def save_to_file(self, file_path=None):
        data = self.to_dict()

        if file_path == None:
            folder = f"wandb/Log/{self.environment_sampler}/{self.environment_curriculum}"
            os.makedirs(folder, exist_ok=True)
            file_path = f"{folder}/latest.json"
        
        with open(file_path, 'w') as f:
            json.dump(data, f)

    @classmethod
    def from_dict(cls, data):
        """
        Deserialize the dictionary into a TerrainContextSpace object.

        Parameters:
        data (dict): The dictionary containing serialized data.
        """
        # Create an instance of TerrainContextSpace
        fake_cfg = BaseVehicleCfg()
        obj = cls(fake_cfg)
        
        # Restore the attributes
        obj.environment_sampler = data['environment_sampler']
        obj.environment_curriculum = data['environment_curriculum']
        obj.method = data['method']
        obj.device = torch.device(data['device'])
        obj.num_rows = data['num_rows']
        obj.num_cols = data['num_cols']
        obj.num_terrains = data['num_terrains']
        obj.num_rows_per_env = data['num_rows_per_env']
        obj.num_cols_per_env = data['num_cols_per_env']
        obj.epoch = data['epoch']
        obj.start_time = data['start_time']
        obj.difficulty = data['difficulty']
        obj.data = pd.DataFrame(data['data'])
        obj.evaluation = pd.DataFrame(data['evaluation'])
        
        return obj

    def retrieve_context(self, r):
        terrain_context_data = r.get('terrain_context')
        if terrain_context_data is None:
            raise ValueError("No terrain context found in Redis!")
        terrain_context_dict = json.loads(terrain_context_data)
        terrain_context_tmp = TerrainContextSpace.from_dict(terrain_context_dict)
        self.__dict__.update(terrain_context_tmp.__dict__)

    def evaluate(self, redis_):
        # Update the old environments statistics
        if self.environment_sampler == 'adaptive':
            max_episode = self.data['episode'].max()
            filtered_data = self.data[(self.data['suc_rate'] < 0.85) & (self.data['episode'] < max_episode)]
            if len(filtered_data) > 1000:
                filtered_data = filtered_data.nsmallest(1000, 'suc_rate')

            if len(filtered_data) > 0:
                groups = np.array_split(filtered_data, np.ceil(len(filtered_data) / 100))
                groups = [pd.DataFrame(group, columns=filtered_data.columns) for group in groups]

                last_group = groups[-1]
                if len(last_group) < 100:
                    # Take additional rows from remaining_data to complete the last group
                    remaining_data = self.data[self.data.index.isin(filtered_data.index)]
                    rows_needed = 100 - len(last_group)
                    additional_rows = remaining_data.head(rows_needed)
                    groups[-1] = pd.concat([last_group, additional_rows])

                # Process each group
                for idx, group in enumerate(groups):
                    self.data['active'] = False
                    self.data.loc[group.index, 'active'] = True

                    print(f"Group {idx + 1}: {len(group)} rows")
                    
                    # Convert the group DataFrame to a TIFF file
                    elevation_file = self.array_to_txt(group)

                    program = [
                        'python3', '-m', 'rl_agents.evaluate_teacher', 
                        '--tif_name', elevation_file,
                        '--tif_index', '0', 
                        '--backbone', self.get_backbone(self.epoch),
                        '--project', 'Offroad Navigation', 
                        '--method', self.method,
                        '--wandb', 'False',
                        '--save', 'False',
                    ]

                    print(f"Executing: {program}")
                    subprocess.call(program)
                    self.retrieve_context(redis_)
    
    def update(self, envs_success_rate, episode):
        active_indices = self.data[self.data['active'] == True].index
        
        if len(envs_success_rate) != len(active_indices):
            raise ValueError("The length of envs_success_rate must match the number of active environments.")
        
        self.data.loc[active_indices, 'suc_rate'] = envs_success_rate
        self.data.loc[active_indices, 'episode'] = episode
    
    def add(self, episode, trajectory, reward, suc_rate):
        new_row = {'episode': episode, 'trajectory': trajectory, 'reward': reward, 'suc_rate': suc_rate}
        self.evaluation = pd.concat([self.evaluation, pd.DataFrame([new_row])], ignore_index=True)

    def array_to_txt(self, sampled_data):
        combined_array = np.zeros((self.num_rows*self.num_rows_per_env, self.num_cols*self.num_cols_per_env))
        for i in range(len(sampled_data)):
            arr = np.loadtxt(sampled_data.iloc[i]['image_name'], delimiter=',')
            row = i // self.num_cols * self.num_rows_per_env
            col = i % self.num_cols * self.num_cols_per_env
            combined_array[row:row+self.num_rows_per_env, col:col+self.num_cols_per_env] = arr

        # Generate a filename with the current timestamp
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        folder = f"wandb/Log/{self.environment_sampler}/{self.environment_curriculum}/{self.epoch}"
        os.makedirs(folder, exist_ok=True)
        elevation_filename = f"{folder}/{timestamp}_batch.txt"

        np.savetxt(elevation_filename, combined_array.astype(np.float32), delimiter=',')

        return elevation_filename

    def random_sample(self):
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        if self.environment_sampler == 'ddpm':
            ddpm_samples = self.ddpm.sample(self.num_terrains) * 20
            ddpm_samples = torch.squeeze(ddpm_samples, dim=1)

        folder = f"wandb/Log/{self.environment_sampler}/{self.environment_curriculum}/{self.epoch}"
        os.makedirs(folder, exist_ok=True)
        for n in range(self.num_terrains):
            if self.environment_sampler == 'procedural':
                new_terrain = self.procedural_sample(-1, -1)
            elif self.environment_sampler  == 'ddpm':
                new_terrain = ddpm_samples[n].cpu().numpy()

            txt_filename = f"{folder}/{timestamp}_{n}.txt"
            np.savetxt(txt_filename, new_terrain, delimiter=',')
            new_row = {'image_name': txt_filename, 'suc_rate': 0, 'episode': 0, 'active': False}
            self.data = pd.concat([self.data, pd.DataFrame([new_row])], ignore_index=True)
    
    def adaptive_sample(self):
        easy = self.data[self.data['suc_rate'] > 0.85].reset_index(drop=True)
        hard = self.data[self.data['suc_rate'] < 0.6].reset_index(drop=True)
        
        if self.environment_sampler == 'ddpm':
            union = pd.concat([easy, hard], ignore_index=True)
            if easy.empty | hard.empty:
                ddpm_samples = self.ddpm.sample(self.num_terrains) * 20
                ddpm_samples = torch.squeeze(ddpm_samples, dim=1)
                new_successes = None
            elif len(union) > 0:
                combined_data = np.array([np.loadtxt(file_name, delimiter=',') for file_name in union['image_name'].tolist()])
                combined_tensor = torch.tensor(combined_data, dtype=torch.float32, device=self.device)
                # Step 1: Center the data (subtract the mean from each feature)
                mean_tensor = torch.mean(combined_tensor, dim=0)
                centered_data = combined_tensor - mean_tensor
                # Step 2: Compute the covariance matrix for the combined data
                U, S, V = torch.pca_lowrank(centered_data)
                normalized_variances = torch.var(centered_data, unbiased=False)
                forward_k = int(max(100, min(1000 * (1 - normalized_variances.item()), 1000)))
                # Step 3: Softmax Weights
                suc_rate_tensor = torch.tensor(union['suc_rate'].values, dtype=torch.float32, device=self.device)
                expect_suc = 0.6
                weights = -torch.pow(suc_rate_tensor - expect_suc, 2) / 0.5
                softmax_weights = torch.nn.functional.softmax(weights, dim=0)
                # Step 4: Sample N terrains
                easy_ = easy.sample(self.num_terrains, replace=True)
                hard_ = hard.sample(self.num_terrains, replace=True)
                easy_samples = [torch.from_numpy(np.loadtxt(path, delimiter=',')).to(device=self.device).float().unsqueeze(0).unsqueeze(0) 
                                for path in easy_['image_name'].values]
                easy_samples = torch.stack(easy_samples).squeeze(1)
                hard_samples = [torch.from_numpy(np.loadtxt(path, delimiter=',')).to(device=self.device).float().unsqueeze(0).unsqueeze(0) 
                                for path in hard_['image_name'].values]
                hard_samples = torch.stack(hard_samples).squeeze(1)
                # Step 5: Estimate interpolation weights
                easy_weights = softmax_weights[easy_.index]
                hard_weights = softmax_weights[hard_.index + len(easy)]
                # Step 6: Estimate success rates
                new_successes = (easy_weights * suc_rate_tensor[easy_.index] + 
                                 hard_weights * suc_rate_tensor[hard_.index + len(easy)]) / (easy_weights + hard_weights)
                # Step 7: Fusion
                lam_ = hard_weights / (easy_weights + hard_weights)
                lam_ = lam_.view(-1, 1, 1, 1)
                ddpm_samples = self.ddpm.interpolate(easy_samples, hard_samples, t = forward_k, lam = lam_) * 20
                ddpm_samples = torch.squeeze(ddpm_samples, dim=1)

        elif self.environment_sampler == 'procedural':
            complement = self.data[(self.data['suc_rate'] >= 0.6) & (self.data['suc_rate'] <= 0.85)].reset_index(drop=True)
            if easy.empty:
                self.difficulty = max(self.difficulty - 1, 0)
            elif hard.empty:
                self.difficulty = min(self.difficulty + 1, 100)
            elif len(easy) < len(hard):
                self.difficulty = max(self.difficulty - 1, 0)
            elif len(easy) > len(hard):
                self.difficulty = min(self.difficulty + 1, 100)
        
        timestamp = time.strftime("%Y%m%d-%H%M%S")
        for n in range(self.num_terrains):
            new_success = 0.1
            if self.environment_sampler == 'procedural':
                new_terrain = self.procedural_sample(-1, self.difficulty)
            elif self.environment_sampler == 'ddpm':
                new_terrain = ddpm_samples[n].cpu().numpy()
                if new_successes is not None:
                    new_success = new_successes[n].item()
            else:
                return

            folder = f"wandb/Log/{self.environment_sampler}/{self.environment_curriculum}/{self.epoch}"
            os.makedirs(folder, exist_ok=True)
            txt_filename = f"{folder}/{timestamp}_{n}.txt"
            np.savetxt(txt_filename, new_terrain, delimiter=',')
            new_row = {'image_name': txt_filename, 'suc_rate': new_success, 'episode': 0, 'active': False}
            self.data = pd.concat([self.data, pd.DataFrame([new_row])], ignore_index=True)
    
    def sample(self, slice_start=None):
        if slice_start != None:
            # Slice the DataFrame
            start_idx = slice_start * self.num_terrains
            end_idx = (slice_start + 1) * self.num_terrains
            sampled_data = self.data.iloc[start_idx:end_idx]
            return self.array_to_txt(sampled_data)
        
        if self.environment_curriculum == 'uniform':
            if self.environment_sampler in {'ddpm', 'procedural'}:
                self.random_sample()
            sampled_data = self.data.sample(n=self.num_terrains)
        elif self.environment_curriculum == 'adaptive':
            if (self.environment_sampler in {'ddpm', 'procedural'}) and len(self.data) < self.num_terrains:
                self.random_sample()
            else:
                self.adaptive_sample()
            
            filtered_df = self.data[(self.data['suc_rate'] >= 0.6) & (self.data['suc_rate'] <= 0.85)]
            if filtered_df.empty:
                filtered_df = self.data[(self.data['suc_rate'] > 0.) & (self.data['suc_rate'] <= 0.85)]
            if filtered_df.empty:
                sampled_data = self.data.sample(n=self.num_terrains)
            else:
                if len(filtered_df) < self.num_terrains:
                    remaining_samples = self.num_terrains - len(filtered_df)
                    remaining_data = self.data[~self.data.index.isin(filtered_df.index)].sample(n=remaining_samples)
                    sampled_data = pd.concat([filtered_df, remaining_data])
                else:
                    suc_rate_tensor = torch.tensor(filtered_df['suc_rate'].values, dtype=torch.float32, device=self.device)
                    expect_suc = 0.6
                    weights = -torch.pow(suc_rate_tensor - expect_suc, 2) / 0.5
                    softmax_weights = torch.nn.functional.softmax(weights, dim=0).cpu().numpy()
                    sampled_data = filtered_df.sample(n=self.num_terrains, weights=softmax_weights)

        self.data['active'] = False
        self.data.loc[sampled_data.index, 'active'] = True

        return self.array_to_txt(sampled_data)